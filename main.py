import pyaudio
import wave
from scipy.fft import rfft, rfftfreq
import numpy as np
import matplotlib.pyplot as plt


class Listener:
    def __init__(self, duration, device_name):
        """Duration: Time to listen for, in milliseconds"""
        self.duration = duration/1000
        self.p = pyaudio.PyAudio()
        self.chunk = 1024
        self.sample_format = pyaudio.paInt16
        self.channels = 1
        self.fs = 44100
        self.filename = "output.wav"

        self.device = 0
        for i in range(self.p.get_device_count()):
            if self.p.get_device_info_by_index(i)["name"] == device_name:
                self.device = i

    def listen(self):
        # Open a stream
        stream = self.p.open(
            format=self.sample_format,
            channels=self.channels,
            rate=self.fs,
            frames_per_buffer=self.chunk,
            input=True,
            input_device_index=self.device
        )
        frames = []

        # Record for duration time
        for i in range(0, int(self.fs / self.chunk * self.duration)):
            data = stream.read(self.chunk)
            frames.append(data)

        # Convert from bytes to PCM
        # Values are stored as signed 16 bit integers, in little endian format. This parses them.
        new_frame = []
        for y in range(len(frames)):
            new_frame += self.convert_bytes(frames[y])

        return new_frame

        # Save the recorded data as a WAV file
        wf = wave.open(self.filename, 'wb')
        wf.setnchannels(self.channels)
        wf.setsampwidth(self.p.get_sample_size(self.sample_format))
        wf.setframerate(self.fs)
        wf.writeframes(b''.join(frames))
        wf.close()

    @staticmethod
    def convert_bytes(_bytes):
        new_frame = []
        for i in range(len(_bytes) // 2):
            sample = _bytes[i * 2:i * 2 + 2]
            int_value = int.from_bytes(sample, byteorder="little", signed=True)
            new_frame.append(int_value)
        return new_frame


def parse_intervals_overlap(file, interval=0.25, times=5):
    wf = wave.open(file, "rb")
    rate = wf.getframerate()
    num_samples = int(rate * (interval/2))  # Read the audio in chunks of this size.
    previous_audio = wf.readframes(num_samples)

    for i in range(times):
        fig, ax = plt.subplots()
        curr_audio = wf.readframes(num_samples)
        audio = previous_audio + curr_audio
        audio = Listener.convert_bytes(audio)

        yf = rfft(audio)  # Gets the transform. Imaginary numbers.
        xf = rfftfreq(len(audio), 1 / wf.getframerate())  # This calculates the "grouping" of frequencies. Might be able to mess with this for my ranges

        peak1 = get_range_sum(xf, yf, 215, 240)
        peak2 = get_range_sum(xf, yf, 260, 330)
        #print([abs(x) for x in yf[0:10]])
        #print(xf[0:10:1])

        ax.set_ylim([0, 300000])
        ax.set_xlim([150, 600])
        ax.plot(xf, np.abs(yf))
        ax.set_title(f"{(interval/2)*i} to {(interval/2)*(i+2)}")

        previous_audio = curr_audio
    plt.show()


def get_range_sum(xf, yf, low, high):
    """Gets the total amplitude of a given range of frequencies.

    Arguments:
        xf: A list of frequencies, generated by rfftfreq
        yf: The amplitudes of frequencies, generated by rfft
        low: Lower bound of frequency to capture
        high: Upper bound of frequency to capture

    returns: The amplitude of the range of frequencies
    """
    x1 = -1
    for i in range(len(xf)):
        if xf[i] >= low:
            x1 = i
            break
    if x1 == -1:
        raise ValueError

    x2 = -1
    for i in range(len(xf) - x1):
        if xf[i+x1] >= high:
            x2 = i + x1
            break
    if x2 == -1:
        raise ValueError

    return np.sum([abs(x) for x in yf[x1:x2]])


# TODO: For error checking, make the bot log a graph of, and an audio sample of anything that returns a hit.
#  This would allow me to analyse any false positives.

#l = Listener(2000, "Line In (High Definition Audio ")
#frames = l.listen()
#exit()


# peak 1: 215-240
# peak 2: 260-330

# dip 1: 250

# TODO: I need to find a way to compare the values of my graph to its surroundings, to detect when a spike has happened.
#  I could set specific number thresholds. This would be easiest, but will also break fastest.
#  I could compare to the last "frame". This scales with volume, but is complex.
#  I could compare the "shape", E.G peak 1 is about 2.5x bigger than peak 2.
#  I could create a normalized standard for the frequency, similar to "last frame".

parse_intervals_overlap("terr_example_audio.wav")
exit()


# Read audio from wav file.
wf = wave.open("fishing_sound.wav", "rb")
print(wf.getframerate())
frames = wf.readframes(99999999)
frames = Listener.convert_bytes(frames)

yf = rfft(frames)  # Gets the transform. This returns complex numbers.
xf = rfftfreq(len(frames), 1/wf.getframerate())  # This calculates the "grouping" of frequencies. Might be able to mess with this for my ranges.

plt.plot(xf[:100], np.abs(yf)[:100])
plt.show()

exit()


# Number of sample points

N = 600

# sample spacing

T = 1.0 / 800.0

x = np.linspace(0.0, N*T, N, endpoint=False)

y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)

yf = fft(y)

xf = fftfreq(N, T)[:N//2]

plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))

plt.grid()

plt.show()
